{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Pre-requisites:**","metadata":{}},{"cell_type":"code","source":"!curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip install\n!pip install auto-sklearn","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100   209  100   209    0     0    941      0 --:--:-- --:--:-- --:--:--   937\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (49.6.0.post20210108)\nRequirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.7/site-packages (1.19.5)\nRequirement already satisfied: scipy>=0.14.1 in /opt/conda/lib/python3.7/site-packages (1.5.4)\nRequirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from scipy>=0.14.1) (1.19.5)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (1.0.1)\nRequirement already satisfied: scikit-learn<0.25.0,>=0.24.0 in /opt/conda/lib/python3.7/site-packages (0.24.1)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<0.25.0,>=0.24.0) (1.5.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<0.25.0,>=0.24.0) (2.1.0)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<0.25.0,>=0.24.0) (1.19.5)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<0.25.0,>=0.24.0) (1.0.1)\nRequirement already satisfied: dask in /opt/conda/lib/python3.7/site-packages (2021.3.1)\nRequirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from dask) (0.11.1)\nRequirement already satisfied: cloudpickle>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from dask) (1.6.0)\nRequirement already satisfied: partd>=0.3.10 in /opt/conda/lib/python3.7/site-packages (from dask) (1.1.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from dask) (5.3.1)\nRequirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from dask) (0.8.5)\nRequirement already satisfied: locket in /opt/conda/lib/python3.7/site-packages (from partd>=0.3.10->dask) (0.2.1)\nRequirement already satisfied: distributed>=2.2.0 in /opt/conda/lib/python3.7/site-packages (2021.3.1)\nRequirement already satisfied: cloudpickle>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0) (1.6.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0) (49.6.0.post20210108)\nRequirement already satisfied: msgpack>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0) (1.0.2)\nRequirement already satisfied: zict>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0) (2.0.0)\nRequirement already satisfied: psutil>=5.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0) (5.8.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0) (5.3.1)\nRequirement already satisfied: click>=6.6 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0) (7.1.2)\nRequirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0) (2.3.0)\nRequirement already satisfied: tblib>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0) (1.7.0)\nRequirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0) (0.11.1)\nRequirement already satisfied: tornado>=5 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0) (5.0.2)\nRequirement already satisfied: dask>=2021.03.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0) (2021.3.1)\nRequirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from dask>=2021.03.0->distributed>=2.2.0) (0.8.5)\nRequirement already satisfied: partd>=0.3.10 in /opt/conda/lib/python3.7/site-packages (from dask>=2021.03.0->distributed>=2.2.0) (1.1.0)\nRequirement already satisfied: locket in /opt/conda/lib/python3.7/site-packages (from partd>=0.3.10->dask>=2021.03.0->distributed>=2.2.0) (0.2.1)\nRequirement already satisfied: heapdict in /opt/conda/lib/python3.7/site-packages (from zict>=0.1.3->distributed>=2.2.0) (1.0.1)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (5.3.1)\nRequirement already satisfied: pandas>=1.0 in /opt/conda/lib/python3.7/site-packages (1.2.2)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.0) (2.8.1)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.0) (2021.1)\nRequirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.0) (1.19.5)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1.0) (1.15.0)\nCollecting liac-arff\n  Downloading liac-arff-2.5.0.tar.gz (13 kB)\nBuilding wheels for collected packages: liac-arff\n  Building wheel for liac-arff (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11731 sha256=f7ecdccac885fb2d729c9a1a0ba958fb6589664b2ece0d076c4d606c63b54330\n  Stored in directory: /root/.cache/pip/wheels/1f/0f/15/332ca86cbebf25ddf98518caaf887945fbe1712b97a0f2493b\nSuccessfully built liac-arff\nInstalling collected packages: liac-arff\nSuccessfully installed liac-arff-2.5.0\nRequirement already satisfied: ConfigSpace<0.5,>=0.4.14 in /opt/conda/lib/python3.7/site-packages (0.4.18)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.7/site-packages (from ConfigSpace<0.5,>=0.4.14) (2.4.7)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from ConfigSpace<0.5,>=0.4.14) (1.19.5)\nRequirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (from ConfigSpace<0.5,>=0.4.14) (0.29.22)\nCollecting pynisher>=0.6.3\n  Downloading pynisher-0.6.4.tar.gz (11 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from pynisher>=0.6.3) (49.6.0.post20210108)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from pynisher>=0.6.3) (5.8.0)\nBuilding wheels for collected packages: pynisher\n  Building wheel for pynisher (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pynisher: filename=pynisher-0.6.4-py3-none-any.whl size=7043 sha256=d4e10268611acbef01877616f38eba62f59344ddc0409e2394cb1597ce4e21ca\n  Stored in directory: /root/.cache/pip/wheels/42/71/95/7555ec3253e1ba8add72ae5febf1b015d297f3b73ba296d6f6\nSuccessfully built pynisher\nInstalling collected packages: pynisher\nSuccessfully installed pynisher-0.6.4\nCollecting pyrfr<0.9,>=0.8.1\n  Downloading pyrfr-0.8.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n\u001b[K     |████████████████████████████████| 4.0 MB 1.2 MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: pyrfr\nSuccessfully installed pyrfr-0.8.1\nCollecting smac<0.14,>=0.13.1\n  Downloading smac-0.13.1.tar.gz (258 kB)\n\u001b[K     |████████████████████████████████| 258 kB 1.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy>=1.7.1 in /opt/conda/lib/python3.7/site-packages (from smac<0.14,>=0.13.1) (1.19.5)\nRequirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from smac<0.14,>=0.13.1) (1.5.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from smac<0.14,>=0.13.1) (5.8.0)\nRequirement already satisfied: pynisher>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from smac<0.14,>=0.13.1) (0.6.4)\nRequirement already satisfied: ConfigSpace<0.5,>=0.4.14 in /opt/conda/lib/python3.7/site-packages (from smac<0.14,>=0.13.1) (0.4.18)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from smac<0.14,>=0.13.1) (1.0.1)\nRequirement already satisfied: scikit-learn>=0.22.0 in /opt/conda/lib/python3.7/site-packages (from smac<0.14,>=0.13.1) (0.24.1)\nRequirement already satisfied: pyrfr>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from smac<0.14,>=0.13.1) (0.8.1)\nCollecting lazy_import\n  Downloading lazy_import-0.2.2.tar.gz (15 kB)\nRequirement already satisfied: dask in /opt/conda/lib/python3.7/site-packages (from smac<0.14,>=0.13.1) (2021.3.1)\nRequirement already satisfied: distributed in /opt/conda/lib/python3.7/site-packages (from smac<0.14,>=0.13.1) (2021.3.1)\nRequirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (from ConfigSpace<0.5,>=0.4.14->smac<0.14,>=0.13.1) (0.29.22)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.7/site-packages (from ConfigSpace<0.5,>=0.4.14->smac<0.14,>=0.13.1) (2.4.7)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from pynisher>=0.4.1->smac<0.14,>=0.13.1) (49.6.0.post20210108)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.0->smac<0.14,>=0.13.1) (2.1.0)\nRequirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from dask->smac<0.14,>=0.13.1) (0.11.1)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from dask->smac<0.14,>=0.13.1) (5.3.1)\nRequirement already satisfied: cloudpickle>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from dask->smac<0.14,>=0.13.1) (1.6.0)\nRequirement already satisfied: partd>=0.3.10 in /opt/conda/lib/python3.7/site-packages (from dask->smac<0.14,>=0.13.1) (1.1.0)\nRequirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from dask->smac<0.14,>=0.13.1) (0.8.5)\nRequirement already satisfied: locket in /opt/conda/lib/python3.7/site-packages (from partd>=0.3.10->dask->smac<0.14,>=0.13.1) (0.2.1)\nRequirement already satisfied: msgpack>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from distributed->smac<0.14,>=0.13.1) (1.0.2)\nRequirement already satisfied: tblib>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from distributed->smac<0.14,>=0.13.1) (1.7.0)\nRequirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /opt/conda/lib/python3.7/site-packages (from distributed->smac<0.14,>=0.13.1) (2.3.0)\nRequirement already satisfied: click>=6.6 in /opt/conda/lib/python3.7/site-packages (from distributed->smac<0.14,>=0.13.1) (7.1.2)\nRequirement already satisfied: tornado>=5 in /opt/conda/lib/python3.7/site-packages (from distributed->smac<0.14,>=0.13.1) (5.0.2)\nRequirement already satisfied: zict>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from distributed->smac<0.14,>=0.13.1) (2.0.0)\nRequirement already satisfied: heapdict in /opt/conda/lib/python3.7/site-packages (from zict>=0.1.3->distributed->smac<0.14,>=0.13.1) (1.0.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from lazy_import->smac<0.14,>=0.13.1) (1.15.0)\nBuilding wheels for collected packages: smac, lazy-import\n  Building wheel for smac (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for smac: filename=smac-0.13.1-py3-none-any.whl size=252178 sha256=73b82cb3c91d7d05fc298e8c3051c46b6bc2c42f7c40f62c56c360241290ed75\n  Stored in directory: /root/.cache/pip/wheels/35/b9/6b/17b5f3d627b1be6cdcc5357f797bd9e4ea8cbae3d1ff00e621\n  Building wheel for lazy-import (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for lazy-import: filename=lazy_import-0.2.2-py2.py3-none-any.whl size=16486 sha256=66c4517a39f905dc0cbcfda52cd836a7ef604670efff4939d345ef29fbadfa3d\n  Stored in directory: /root/.cache/pip/wheels/e6/8e/c7/c338956a635caa3b3153cd8e49b183badb75230ecf19144dff\nSuccessfully built smac lazy-import\nInstalling collected packages: lazy-import, smac\nSuccessfully installed lazy-import-0.2.2 smac-0.13.1\nCollecting auto-sklearn\n  Downloading auto-sklearn-0.12.5.tar.gz (6.1 MB)\n\u001b[K     |████████████████████████████████| 6.1 MB 1.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from auto-sklearn) (49.6.0.post20210108)\nRequirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from auto-sklearn) (1.19.5)\nRequirement already satisfied: scipy>=0.14.1 in /opt/conda/lib/python3.7/site-packages (from auto-sklearn) (1.5.4)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from auto-sklearn) (1.0.1)\nRequirement already satisfied: scikit-learn<0.25.0,>=0.24.0 in /opt/conda/lib/python3.7/site-packages (from auto-sklearn) (0.24.1)\nRequirement already satisfied: dask in /opt/conda/lib/python3.7/site-packages (from auto-sklearn) (2021.3.1)\nRequirement already satisfied: distributed>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from auto-sklearn) (2021.3.1)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from auto-sklearn) (5.3.1)\nRequirement already satisfied: pandas>=1.0 in /opt/conda/lib/python3.7/site-packages (from auto-sklearn) (1.2.2)\nRequirement already satisfied: liac-arff in /opt/conda/lib/python3.7/site-packages (from auto-sklearn) (2.5.0)\nRequirement already satisfied: ConfigSpace<0.5,>=0.4.14 in /opt/conda/lib/python3.7/site-packages (from auto-sklearn) (0.4.18)\nRequirement already satisfied: pynisher>=0.6.3 in /opt/conda/lib/python3.7/site-packages (from auto-sklearn) (0.6.4)\nRequirement already satisfied: pyrfr<0.9,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from auto-sklearn) (0.8.1)\nRequirement already satisfied: smac<0.14,>=0.13.1 in /opt/conda/lib/python3.7/site-packages (from auto-sklearn) (0.13.1)\nRequirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn) (0.29.22)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.7/site-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn) (2.4.7)\nRequirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0->auto-sklearn) (0.11.1)\nRequirement already satisfied: tblib>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0->auto-sklearn) (1.7.0)\nRequirement already satisfied: cloudpickle>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0->auto-sklearn) (1.6.0)\nRequirement already satisfied: psutil>=5.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0->auto-sklearn) (5.8.0)\nRequirement already satisfied: click>=6.6 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0->auto-sklearn) (7.1.2)\nRequirement already satisfied: tornado>=5 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0->auto-sklearn) (5.0.2)\nRequirement already satisfied: zict>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0->auto-sklearn) (2.0.0)\nRequirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0->auto-sklearn) (2.3.0)\nRequirement already satisfied: msgpack>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.2.0->auto-sklearn) (1.0.2)\nRequirement already satisfied: partd>=0.3.10 in /opt/conda/lib/python3.7/site-packages (from dask->auto-sklearn) (1.1.0)\nRequirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from dask->auto-sklearn) (0.8.5)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.0->auto-sklearn) (2.8.1)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.0->auto-sklearn) (2021.1)\nRequirement already satisfied: locket in /opt/conda/lib/python3.7/site-packages (from partd>=0.3.10->dask->auto-sklearn) (0.2.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1.0->auto-sklearn) (1.15.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<0.25.0,>=0.24.0->auto-sklearn) (2.1.0)\nRequirement already satisfied: lazy-import in /opt/conda/lib/python3.7/site-packages (from smac<0.14,>=0.13.1->auto-sklearn) (0.2.2)\nRequirement already satisfied: heapdict in /opt/conda/lib/python3.7/site-packages (from zict>=0.1.3->distributed>=2.2.0->auto-sklearn) (1.0.1)\nBuilding wheels for collected packages: auto-sklearn\n  Building wheel for auto-sklearn (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for auto-sklearn: filename=auto_sklearn-0.12.5-py3-none-any.whl size=6367617 sha256=973d9fa6eb8785a278bd9cfa4ef7ce7478b5a0d07cd7bcc2ee170decf6d57a1f\n  Stored in directory: /root/.cache/pip/wheels/0d/54/71/61cc11f67d479fbaee740c1aab8d6bde70b202ed0340b12efb\nSuccessfully built auto-sklearn\nInstalling collected packages: auto-sklearn\nSuccessfully installed auto-sklearn-0.12.5\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install dtreeviz\nfrom dtreeviz.trees import dtreeviz","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting dtreeviz\n  Downloading dtreeviz-1.3.tar.gz (60 kB)\n\u001b[K     |████████████████████████████████| 60 kB 890 kB/s eta 0:00:011\n\u001b[?25hCollecting graphviz>=0.9\n  Downloading graphviz-0.16-py2.py3-none-any.whl (19 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from dtreeviz) (1.2.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from dtreeviz) (1.19.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from dtreeviz) (0.24.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from dtreeviz) (3.4.0)\nCollecting colour\n  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\nRequirement already satisfied: pytest in /opt/conda/lib/python3.7/site-packages (from dtreeviz) (6.2.2)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->dtreeviz) (0.10.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->dtreeviz) (2.8.1)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->dtreeviz) (2.4.7)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->dtreeviz) (7.2.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->dtreeviz) (1.3.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->dtreeviz) (1.15.0)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->dtreeviz) (2021.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz) (20.9)\nRequirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz) (3.4.0)\nRequirement already satisfied: toml in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz) (0.10.2)\nRequirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz) (20.3.0)\nRequirement already satisfied: pluggy<1.0.0a1,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz) (0.13.1)\nRequirement already satisfied: py>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz) (1.10.0)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz) (1.1.1)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->dtreeviz) (3.7.4.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->dtreeviz) (3.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->dtreeviz) (2.1.0)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->dtreeviz) (1.5.4)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->dtreeviz) (1.0.1)\nBuilding wheels for collected packages: dtreeviz\n  Building wheel for dtreeviz (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for dtreeviz: filename=dtreeviz-1.3-py3-none-any.whl size=66638 sha256=0cfeb5a21c22a01ae2bb390cb83d0d088b3ab5ef5ad6043d7e5afc4705fc195f\n  Stored in directory: /root/.cache/pip/wheels/9f/a6/a1/898c991294471015f13c1e5b456fb8134c1af835db4dd93a7a\nSuccessfully built dtreeviz\nInstalling collected packages: graphviz, colour, dtreeviz\n  Attempting uninstall: graphviz\n    Found existing installation: graphviz 0.8.4\n    Uninstalling graphviz-0.8.4:\n      Successfully uninstalled graphviz-0.8.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nmxnet 1.8.0.post0 requires graphviz<0.9.0,>=0.8.1, but you have graphviz 0.16 which is incompatible.\nautogluon-core 0.1.0 requires graphviz<0.9.0,>=0.8.1, but you have graphviz 0.16 which is incompatible.\u001b[0m\nSuccessfully installed colour-0.1.5 dtreeviz-1.3 graphviz-0.16\n","output_type":"stream"}]},{"cell_type":"code","source":"\n!pip install -U rfpimp\n!pip install -U imbalanced-learn\n%matplotlib inline\n#importing libraries\nimport numpy as np\nimport scipy.stats\nimport scipy.special\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.mlab as mlab\nfrom matplotlib import cm\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.pipeline import make_pipeline, make_union, Pipeline\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import ParameterGrid\nfrom keras.models import Sequential\nfrom keras.models import Model as KerasModel\nfrom keras.layers import Input, Dense, Activation, Reshape\nfrom keras.layers import Concatenate\nfrom keras.layers.embeddings import Embedding\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import linear_model\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.inspection import permutation_importance\nimport pickle\nimport csv\nimport collections\nfrom rfpimp import *\nfrom rfpimp import plot_corr_heatmap\nfrom datetime import datetime\nfrom sklearn import preprocessing\nfrom keras.callbacks import ModelCheckpoint\nimport xgboost as xgb\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import classification_report\nimport seaborn as sns\nimport imblearn\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import plot_confusion_matrix\nimport math\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.layers import Input, LSTM, Dense, Concatenate,GRU,Dropout,LeakyReLU\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.io import FixedLenFeature\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder, normalize\nimport tensorflow as tf","metadata":{"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting rfpimp\n  Downloading rfpimp-1.3.7.tar.gz (10 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from rfpimp) (1.19.5)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from rfpimp) (1.2.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from rfpimp) (0.24.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from rfpimp) (3.4.0)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->rfpimp) (7.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->rfpimp) (0.10.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->rfpimp) (2.8.1)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->rfpimp) (2.4.7)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->rfpimp) (1.3.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->rfpimp) (1.15.0)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->rfpimp) (2021.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->rfpimp) (1.0.1)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->rfpimp) (1.5.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->rfpimp) (2.1.0)\nBuilding wheels for collected packages: rfpimp\n  Building wheel for rfpimp (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rfpimp: filename=rfpimp-1.3.7-py3-none-any.whl size=10668 sha256=e99d191d128e40b7f81413ef171b194b3cd1ea01cd864d5a2749a86dc6a64fcb\n  Stored in directory: /root/.cache/pip/wheels/ad/48/d9/21fc62fbeff405425b0d5dd8b0354576cdb62ac97f6b11d1ef\nSuccessfully built rfpimp\nInstalling collected packages: rfpimp\nSuccessfully installed rfpimp-1.3.7\nRequirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.7/site-packages (0.8.0)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (1.5.4)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (1.19.5)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (1.0.1)\nRequirement already satisfied: scikit-learn>=0.24 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (0.24.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.24->imbalanced-learn) (2.1.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Datasets:","metadata":{}},{"cell_type":"code","source":"training=pd.read_csv(\"/kaggle/input/higgs-boson/training.zip\")\ntraining.head()","metadata":{"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   EventId  DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\n0   100000       138.470                       51.655        97.827    27.980   \n1   100001       160.937                       68.768       103.235    48.146   \n2   100002      -999.000                      162.172       125.953    35.635   \n3   100003       143.905                       81.417        80.943     0.414   \n4   100004       175.864                       16.915       134.805    16.405   \n\n   DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n0                  0.91           124.711                2.666   \n1               -999.00          -999.000             -999.000   \n2               -999.00          -999.000             -999.000   \n3               -999.00          -999.000             -999.000   \n4               -999.00          -999.000             -999.000   \n\n   DER_deltar_tau_lep  DER_pt_tot  ...  PRI_jet_num  PRI_jet_leading_pt  \\\n0               3.064      41.928  ...            2              67.435   \n1               3.473       2.078  ...            1              46.226   \n2               3.148       9.336  ...            1              44.251   \n3               3.310       0.414  ...            0            -999.000   \n4               3.891      16.405  ...            0            -999.000   \n\n   PRI_jet_leading_eta  PRI_jet_leading_phi  PRI_jet_subleading_pt  \\\n0                2.150                0.444                 46.062   \n1                0.725                1.158               -999.000   \n2                2.053               -2.028               -999.000   \n3             -999.000             -999.000               -999.000   \n4             -999.000             -999.000               -999.000   \n\n   PRI_jet_subleading_eta  PRI_jet_subleading_phi  PRI_jet_all_pt    Weight  \\\n0                    1.24                  -2.475         113.497  0.002653   \n1                 -999.00                -999.000          46.226  2.233584   \n2                 -999.00                -999.000          44.251  2.347389   \n3                 -999.00                -999.000          -0.000  5.446378   \n4                 -999.00                -999.000           0.000  6.245333   \n\n   Label  \n0      s  \n1      b  \n2      b  \n3      b  \n4      b  \n\n[5 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EventId</th>\n      <th>DER_mass_MMC</th>\n      <th>DER_mass_transverse_met_lep</th>\n      <th>DER_mass_vis</th>\n      <th>DER_pt_h</th>\n      <th>DER_deltaeta_jet_jet</th>\n      <th>DER_mass_jet_jet</th>\n      <th>DER_prodeta_jet_jet</th>\n      <th>DER_deltar_tau_lep</th>\n      <th>DER_pt_tot</th>\n      <th>...</th>\n      <th>PRI_jet_num</th>\n      <th>PRI_jet_leading_pt</th>\n      <th>PRI_jet_leading_eta</th>\n      <th>PRI_jet_leading_phi</th>\n      <th>PRI_jet_subleading_pt</th>\n      <th>PRI_jet_subleading_eta</th>\n      <th>PRI_jet_subleading_phi</th>\n      <th>PRI_jet_all_pt</th>\n      <th>Weight</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100000</td>\n      <td>138.470</td>\n      <td>51.655</td>\n      <td>97.827</td>\n      <td>27.980</td>\n      <td>0.91</td>\n      <td>124.711</td>\n      <td>2.666</td>\n      <td>3.064</td>\n      <td>41.928</td>\n      <td>...</td>\n      <td>2</td>\n      <td>67.435</td>\n      <td>2.150</td>\n      <td>0.444</td>\n      <td>46.062</td>\n      <td>1.24</td>\n      <td>-2.475</td>\n      <td>113.497</td>\n      <td>0.002653</td>\n      <td>s</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100001</td>\n      <td>160.937</td>\n      <td>68.768</td>\n      <td>103.235</td>\n      <td>48.146</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.473</td>\n      <td>2.078</td>\n      <td>...</td>\n      <td>1</td>\n      <td>46.226</td>\n      <td>0.725</td>\n      <td>1.158</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>46.226</td>\n      <td>2.233584</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100002</td>\n      <td>-999.000</td>\n      <td>162.172</td>\n      <td>125.953</td>\n      <td>35.635</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.148</td>\n      <td>9.336</td>\n      <td>...</td>\n      <td>1</td>\n      <td>44.251</td>\n      <td>2.053</td>\n      <td>-2.028</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>44.251</td>\n      <td>2.347389</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100003</td>\n      <td>143.905</td>\n      <td>81.417</td>\n      <td>80.943</td>\n      <td>0.414</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.310</td>\n      <td>0.414</td>\n      <td>...</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-0.000</td>\n      <td>5.446378</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100004</td>\n      <td>175.864</td>\n      <td>16.915</td>\n      <td>134.805</td>\n      <td>16.405</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.891</td>\n      <td>16.405</td>\n      <td>...</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>0.000</td>\n      <td>6.245333</td>\n      <td>b</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 33 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"testing=pd.read_csv(\"/kaggle/input/higgs-boson/test.zip\")\ntesting.set_index('EventId',inplace=True)\ntesting.head()","metadata":{"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"         DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\nEventId                                                                      \n350000       -999.000                       79.589        23.916     3.036   \n350001        106.398                       67.490        87.949    49.994   \n350002        117.794                       56.226        96.358     4.137   \n350003        135.861                       30.604        97.288     9.104   \n350004         74.159                       82.772        58.731    89.646   \n\n         DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\nEventId                                                                \n350000               -999.000          -999.000             -999.000   \n350001               -999.000          -999.000             -999.000   \n350002               -999.000          -999.000             -999.000   \n350003               -999.000          -999.000             -999.000   \n350004                  1.347           536.663               -0.339   \n\n         DER_deltar_tau_lep  DER_pt_tot  DER_sum_pt  ...  PRI_met_phi  \\\nEventId                                              ...                \n350000                0.903       3.036      56.018  ...        2.022   \n350001                2.048       2.679     132.865  ...       -1.138   \n350002                2.755       4.137      97.600  ...       -1.868   \n350003                2.811       9.104      94.112  ...        1.172   \n350004                1.028      77.213     721.552  ...       -0.231   \n\n         PRI_met_sumet  PRI_jet_num  PRI_jet_leading_pt  PRI_jet_leading_eta  \\\nEventId                                                                        \n350000          98.556            0            -999.000             -999.000   \n350001         176.251            1              47.575               -0.553   \n350002         111.505            0            -999.000             -999.000   \n350003         164.707            0            -999.000             -999.000   \n350004         869.614            3             254.085               -1.013   \n\n         PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\nEventId                                                                       \n350000              -999.000               -999.000                -999.000   \n350001                -0.849               -999.000                -999.000   \n350002              -999.000               -999.000                -999.000   \n350003              -999.000               -999.000                -999.000   \n350004                -0.334                185.857                   0.335   \n\n         PRI_jet_subleading_phi  PRI_jet_all_pt  \nEventId                                          \n350000                 -999.000          -0.000  \n350001                 -999.000          47.575  \n350002                 -999.000           0.000  \n350003                 -999.000           0.000  \n350004                    2.587         599.213  \n\n[5 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DER_mass_MMC</th>\n      <th>DER_mass_transverse_met_lep</th>\n      <th>DER_mass_vis</th>\n      <th>DER_pt_h</th>\n      <th>DER_deltaeta_jet_jet</th>\n      <th>DER_mass_jet_jet</th>\n      <th>DER_prodeta_jet_jet</th>\n      <th>DER_deltar_tau_lep</th>\n      <th>DER_pt_tot</th>\n      <th>DER_sum_pt</th>\n      <th>...</th>\n      <th>PRI_met_phi</th>\n      <th>PRI_met_sumet</th>\n      <th>PRI_jet_num</th>\n      <th>PRI_jet_leading_pt</th>\n      <th>PRI_jet_leading_eta</th>\n      <th>PRI_jet_leading_phi</th>\n      <th>PRI_jet_subleading_pt</th>\n      <th>PRI_jet_subleading_eta</th>\n      <th>PRI_jet_subleading_phi</th>\n      <th>PRI_jet_all_pt</th>\n    </tr>\n    <tr>\n      <th>EventId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>350000</th>\n      <td>-999.000</td>\n      <td>79.589</td>\n      <td>23.916</td>\n      <td>3.036</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>0.903</td>\n      <td>3.036</td>\n      <td>56.018</td>\n      <td>...</td>\n      <td>2.022</td>\n      <td>98.556</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-0.000</td>\n    </tr>\n    <tr>\n      <th>350001</th>\n      <td>106.398</td>\n      <td>67.490</td>\n      <td>87.949</td>\n      <td>49.994</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>2.048</td>\n      <td>2.679</td>\n      <td>132.865</td>\n      <td>...</td>\n      <td>-1.138</td>\n      <td>176.251</td>\n      <td>1</td>\n      <td>47.575</td>\n      <td>-0.553</td>\n      <td>-0.849</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>47.575</td>\n    </tr>\n    <tr>\n      <th>350002</th>\n      <td>117.794</td>\n      <td>56.226</td>\n      <td>96.358</td>\n      <td>4.137</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>2.755</td>\n      <td>4.137</td>\n      <td>97.600</td>\n      <td>...</td>\n      <td>-1.868</td>\n      <td>111.505</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>350003</th>\n      <td>135.861</td>\n      <td>30.604</td>\n      <td>97.288</td>\n      <td>9.104</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>2.811</td>\n      <td>9.104</td>\n      <td>94.112</td>\n      <td>...</td>\n      <td>1.172</td>\n      <td>164.707</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>350004</th>\n      <td>74.159</td>\n      <td>82.772</td>\n      <td>58.731</td>\n      <td>89.646</td>\n      <td>1.347</td>\n      <td>536.663</td>\n      <td>-0.339</td>\n      <td>1.028</td>\n      <td>77.213</td>\n      <td>721.552</td>\n      <td>...</td>\n      <td>-0.231</td>\n      <td>869.614</td>\n      <td>3</td>\n      <td>254.085</td>\n      <td>-1.013</td>\n      <td>-0.334</td>\n      <td>185.857</td>\n      <td>0.335</td>\n      <td>2.587</td>\n      <td>599.213</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"*Here, we have the two datasets of the Higg Boson Challenge of 2014 which had the data for categorising the events as either a signal event or a background event. The accuracy of the classification model is to be calculated using the approximate median significance. The weights of each of the cases are also given.*","metadata":{}},{"cell_type":"code","source":"print(training.shape,testing.shape)","metadata":{"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(250000, 33) (550000, 30)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataX=training.drop([\"Weight\",\"Label\"],axis=1)\ntrain_dataX.set_index('EventId',inplace=True)\ntrain_dataY=training['Label']\n","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_dataY=pd.factorize(train_dataY)[0]","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display, HTML\n\ndef pretty_print(df):\n    return display( HTML( df.to_html().replace(\"\\\\n\",\"<br>\") ) )\ndef tbl_report(tbl, cols=None, card=10):\n    print(\"Table Shape\", tbl.shape)\n    dtypes = tbl.dtypes\n    nulls = []\n    uniques = []\n    numuniques = []\n    vcs = []\n    for col in dtypes.index:\n        n = tbl[col].isnull().sum()\n        nulls.append(n)\n        strdtcol = str(dtypes[col])\n        #if strdtcol == 'object' or strdtcol[0:3] == 'int' or strdtcol[0:3] == 'int':\n        #print(strdtcol)\n        uniqs = tbl[col].unique()\n        uniquenums = uniqs.shape[0]\n        if uniquenums < card: # low cardinality\n            valcounts = pd.value_counts(tbl[col], dropna=False)\n            vc = \"\\n\".join([\"{}:{}\".format(k,v) for k, v in valcounts.items()])\n        else:\n            vc='HC' # high cardinality\n        uniques.append(uniqs)\n        numuniques.append(uniquenums)\n        vcs.append(vc)\n    nullseries = pd.Series(nulls, index=dtypes.index)\n    uniqueseries = pd.Series(uniques, index=dtypes.index)\n    numuniqueseries = pd.Series(numuniques, index=dtypes.index)\n    vcseries = pd.Series(vcs, index=dtypes.index)\n    df = pd.concat([dtypes, nullseries, uniqueseries, numuniqueseries, vcseries], axis=1)\n    df.columns = ['dtype', 'nulls', 'uniques', 'num_uniques', 'value_counts']\n    if cols:\n        return pretty_print(df[cols])\n    return pretty_print(df)","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"**We will have a look at our training dataset before we run any EDA,Feature Engineering or Modelling**","metadata":{}},{"cell_type":"code","source":"tbl_report(train_dataX)","metadata":{"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Table Shape (250000, 30)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dtype</th>\n      <th>nulls</th>\n      <th>uniques</th>\n      <th>num_uniques</th>\n      <th>value_counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>DER_mass_MMC</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[138.47, 160.937, -999.0, 143.905, 175.864, 89.744, 148.754, 154.916, 105.594, 128.053, 114.744, 145.297, 82.488, 111.026, 114.256, 127.861, 90.736, 87.075, 141.481, 110.785, 76.883, 137.197, 111.271, 118.104, 98.761, 121.681, 129.186, 123.112, 156.894, 72.712, 134.153, 155.487, 138.362, 120.506, 109.684, 90.833, 122.516, 132.049, 84.86, 27.788, 201.473, 130.079, 167.534, 95.407, 219.057, 104.142, 219.292, 51.025, 148.523, 104.221, 73.819, 103.646, 122.934, 139.394, 92.065, 92.696, 83.081, 123.715, 94.229, 88.532, 101.675, 120.253, 96.906, 92.222, 98.597, 239.551, 86.629, 132.35, 123.29, 84.608, 166.64, 145.99, 99.668, 199.9, 92.079, 117.247, 235.976, 151.45, 124.118, 96.97, 96.379, 111.356, 98.181, 113.75, 124.575, 77.578, 107.35, 90.801, 95.787, 101.079, 130.123, 130.634, 208.573, 91.616, 109.829, 90.331, 114.661, 139.756, 87.523, 287.995, ...]</td>\n      <td>108338</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>DER_mass_transverse_met_lep</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[51.655, 68.768, 162.172, 81.417, 16.915, 13.55, 28.862, 10.418, 50.559, 88.941, 86.24, 10.286, 64.234, 31.663, 109.412, 32.096, 4.351, 50.953, 85.186, 88.767, 89.705, 18.674, 38.217, 0.736, 72.927, 34.384, 68.009, 27.18, 2.633, 14.024, 91.316, 6.041, 64.045, 62.758, 39.256, 20.762, 23.856, 61.072, 38.034, 22.729, 42.664, 62.236, 50.183, 65.682, 33.706, 68.032, 23.002, 53.335, 41.277, 21.584, 72.461, 37.94, 83.924, 98.947, 74.6, 50.315, 110.686, 31.911, 13.816, 83.737, 40.918, 73.141, 71.611, 65.274, 51.669, 63.334, 57.088, 78.683, 16.345, 72.911, 30.144, 70.619, 71.751, 16.05, 65.71, 41.715, 118.683, 33.856, 65.858, 52.954, 50.05, 65.312, 15.868, 68.862, 25.986, 71.692, 78.686, 42.327, 102.167, 55.918, 39.326, 59.132, 61.769, 17.118, 20.265, 68.298, 52.067, 34.558, 72.277, 20.354, ...]</td>\n      <td>101637</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>DER_mass_vis</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[97.827, 103.235, 125.953, 80.943, 134.805, 59.149, 107.782, 94.714, 100.989, 69.272, 79.692, 75.712, 103.565, 64.128, 14.398, 75.271, 67.963, 77.267, 68.827, 115.058, 41.765, 60.231, 67.041, 111.581, 82.775, 56.993, 78.296, 70.642, 77.31, 74.23, 51.771, 73.202, 69.499, 86.702, 122.894, 50.255, 100.96, 125.013, 99.038, 88.889, 86.064, 53.228, 87.682, 87.937, 67.847, 23.53, 104.041, 97.435, 123.308, 67.766, 124.835, 69.029, 136.152, 85.408, 177.143, 46.006, 65.448, 97.497, 71.225, 60.659, 64.244, 68.069, 78.711, 53.52, 68.835, 60.631, 81.811, 69.352, 50.14, 49.453, 82.176, 81.224, 74.602, 64.769, 56.525, 78.618, 193.111, 67.5, 106.57, 76.946, 63.451, 50.047, 80.477, 97.342, 60.637, 52.779, 167.085, 71.28, 79.738, 175.744, 108.268, 77.775, 93.213, 63.373, 50.19, 77.216, 76.262, 100.197, 58.168, 77.755, ...]</td>\n      <td>100558</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>DER_pt_h</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[27.98, 48.146, 35.635, 0.414, 16.405, 116.344, 106.13, 29.169, 4.288, 193.392, 27.201, 30.816, 106.999, 8.232, 17.323, 23.067, 47.221, 26.967, 5.042, 15.337, 18.437, 25.156, 2.347, 174.075, 30.888, 5.569, 35.332, 144.766, 91.388, 132.806, 33.742, 198.114, 63.165, 39.901, 71.682, 39.263, 9.377, 2.768, 65.021, 35.999, 0.23, 21.581, 102.403, 0.861, 18.079, 33.375, 60.49, 1.382, 9.909, 1.482, 5.506, 50.58, 40.286, 1.578, 2.423, 1.303, 49.395, 171.074, 27.029, 43.435, 135.726, 4.647, 28.947, 28.173, 39.384, 38.653, 53.612, 25.679, 95.309, 42.633, 38.736, 23.097, 39.664, 3.422, 1.118, 3.375, 6.549, 49.081, 124.84, 129.157, 0.658, 0.515, 77.915, 28.538, 192.267, 2.705, 77.236, 29.118, 34.164, 39.662, 19.727, 0.419, 0.51, 71.039, 104.878, 1.17, 1.25, 161.051, 153.606, 89.044, ...]</td>\n      <td>115563</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>DER_deltaeta_jet_jet</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[0.91, -999.0, 2.636, 0.733, 2.563, 1.955, 4.936, 3.676, 2.639, 5.087, 3.16, 1.814, 0.218, 3.28, 1.37, 4.437, 3.941, 0.482, 1.209, 1.494, 0.68, 4.557, 3.918, 2.978, 5.822, 1.575, 4.664, 1.048, 0.726, 6.108, 3.243, 2.604, 4.449, 0.237, 2.463, 3.022, 2.685, 3.655, 2.893, 4.868, 0.313, 4.023, 0.69, 0.698, 4.761, 0.006, 2.594, 0.9, 5.762, 3.015, 0.833, 0.191, 0.718, 0.918, 1.441, 0.019, 4.261, 4.297, 2.675, 0.463, 1.127, 0.617, 0.065, 4.035, 0.441, 0.916, 3.66, 2.541, 0.647, 3.342, 3.483, 0.661, 1.124, 3.384, 0.689, 3.723, 2.455, 3.33, 2.678, 0.033, 0.885, 0.334, 5.879, 1.546, 0.829, 4.098, 1.325, 3.602, 0.29, 1.407, 0.039, 5.865, 2.068, 1.43, 1.895, 1.321, 4.641, 3.425, 2.392, 3.805, ...]</td>\n      <td>7087</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>DER_mass_jet_jet</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[124.711, -999.0, 284.584, 158.359, 252.599, 364.344, 1021.322, 315.854, 295.942, 854.799, 244.181, 275.461, 167.175, 479.59, 78.189, 491.375, 411.813, 24.02, 262.61, 162.191, 73.056, 580.126, 407.579, 229.16, 1558.773, 215.121, 396.915, 231.346, 179.399, 1204.243, 324.597, 370.937, 564.836, 146.118, 261.761, 262.128, 183.753, 448.409, 211.215, 463.181, 281.954, 580.409, 61.257, 89.307, 1045.021, 31.827, 301.022, 47.636, 1428.776, 329.862, 40.888, 144.187, 114.918, 69.669, 108.022, 35.411, 725.805, 278.812, 349.038, 246.984, 122.734, 51.069, 553.436, 539.363, 47.634, 128.741, 385.784, 455.956, 106.225, 1056.395, 992.085, 115.48, 103.034, 264.003, 79.004, 295.681, 193.902, 388.324, 153.461, 30.562, 88.122, 77.456, 1325.068, 103.296, 92.345, 575.965, 175.466, 450.124, 86.706, 451.641, 213.357, 1270.326, 346.26, 163.757, 341.207, 116.742, 431.14, 346.612, 278.465, 842.146, ...]</td>\n      <td>68366</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>DER_prodeta_jet_jet</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[2.666, -999.0, -0.54, 0.113, -1.401, -0.923, -5.834, -2.665, -1.738, -6.159, -2.139, 1.506, 5.17, -2.564, 3.443, -4.916, -1.86, 7.901, -0.067, -0.546, 1.649, -3.436, -3.457, -1.67, -8.423, -0.544, -5.149, -0.273, 0.873, -8.309, -2.626, -1.597, -2.99, 3.859, -1.358, -2.12, 0.026, -1.74, 3.061, -3.399, 0.882, -0.919, 2.731, 0.1, -5.662, 0.039, -0.971, 4.808, -8.201, -2.142, -0.037, 0.137, 0.001, 4.662, -0.464, 0.336, -3.512, -2.593, -0.575, -0.039, -0.229, -0.07, 0.025, -3.332, 1.164, 2.503, -1.249, -1.614, 1.149, -2.686, -2.822, 8.697, 0.142, -1.513, 10.32, -2.079, -1.357, -2.692, -1.616, 0.103, 2.916, 0.151, -8.079, 2.658, -0.002, -3.336, -0.37, -2.435, 2.408, 0.514, 0.356, -8.023, -1.067, 0.228, -0.04, 0.487, -5.381, -1.545, -0.512, -3.078, ...]</td>\n      <td>16593</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>DER_deltar_tau_lep</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[3.064, 3.473, 3.148, 3.31, 3.891, 1.362, 2.941, 2.897, 2.904, 1.609, 2.338, 2.888, 2.183, 2.823, 0.472, 3.205, 2.954, 2.833, 2.116, 2.879, 1.395, 2.363, 2.852, 1.335, 3.032, 2.912, 2.883, 1.795, 1.976, 1.261, 1.309, 1.148, 2.745, 2.825, 2.387, 2.186, 2.846, 2.908, 2.605, 2.465, 2.629, 1.881, 2.952, 2.346, 0.78, 2.968, 3.023, 2.776, 3.042, 3.771, 2.448, 3.111, 2.598, 4.054, 2.109, 2.893, 1.423, 2.836, 1.576, 1.524, 2.992, 2.945, 2.738, 2.513, 2.077, 3.043, 2.507, 1.771, 2.551, 1.724, 2.348, 2.824, 2.012, 2.409, 2.857, 1.951, 1.931, 1.769, 2.961, 2.13, 2.871, 3.088, 1.405, 1.985, 2.934, 2.322, 3.23, 2.69, 3.387, 3.112, 2.782, 1.677, 2.5, 2.918, 2.962, 1.479, 0.988, 2.482, 2.457, 2.266, ...]</td>\n      <td>4692</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>DER_pt_tot</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[41.928, 2.078, 9.336, 0.414, 16.405, 61.619, 2.545, 1.526, 4.288, 28.859, 27.201, 36.745, 24.66, 8.232, 17.323, 23.067, 26.243, 26.967, 5.042, 15.337, 18.437, 25.156, 2.347, 6.663, 30.888, 5.569, 0.204, 0.367, 21.536, 23.29, 0.876, 31.017, 6.58, 9.732, 29.365, 21.817, 9.377, 2.768, 97.25, 32.706, 0.23, 21.581, 0.731, 0.861, 18.079, 10.201, 1.786, 1.382, 9.909, 1.482, 46.936, 4.194, 40.286, 1.578, 2.423, 1.303, 26.385, 20.859, 27.029, 45.807, 18.535, 4.647, 2.399, 28.173, 15.701, 0.91, 53.612, 25.679, 34.156, 42.633, 46.301, 23.097, 14.617, 3.422, 1.118, 3.375, 6.549, 17.799, 34.787, 26.758, 0.658, 74.884, 28.035, 24.909, 37.955, 2.705, 17.233, 29.118, 1.991, 3.627, 4.789, 0.419, 0.51, 22.278, 26.905, 1.17, 1.25, 61.347, 41.756, 31.871, ...]</td>\n      <td>59042</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>DER_sum_pt</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[197.76, 125.157, 197.814, 75.968, 57.983, 278.876, 305.967, 138.178, 65.333, 255.123, 81.734, 239.804, 192.245, 58.649, 62.565, 69.649, 100.93, 79.503, 71.443, 58.211, 57.157, 64.833, 65.281, 440.859, 77.888, 58.116, 115.081, 309.992, 159.743, 239.33, 112.809, 412.518, 203.08, 184.194, 148.381, 103.596, 101.789, 123.704, 403.267, 294.349, 82.944, 55.182, 297.49, 87.374, 73.32, 132.965, 247.731, 93.255, 124.886, 67.894, 122.986, 185.688, 67.818, 89.173, 71.678, 52.149, 138.2, 420.089, 70.783, 273.216, 305.027, 74.409, 110.117, 54.346, 123.58, 111.277, 82.428, 71.802, 187.654, 51.687, 243.103, 122.205, 107.103, 66.948, 66.151, 86.58, 181.614, 204.93, 303.37, 224.796, 57.911, 132.893, 410.568, 174.47, 435.679, 50.751, 172.545, 73.226, 108.514, 193.94, 305.546, 75.391, 70.954, 206.663, 138.893, 63.11, 77.982, 315.354, 330.67, 233.139, ...]</td>\n      <td>156098</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>DER_pt_ratio_lep_tau</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[1.582, 0.879, 3.776, 2.354, 1.056, 0.588, 3.371, 0.365, 0.675, 0.599, 1.75, 1.061, 0.576, 1.303, 1.774, 1.276, 1.145, 1.586, 1.558, 0.875, 1.082, 0.749, 0.652, 2.581, 1.492, 1.295, 2.848, 1.172, 1.541, 1.718, 0.262, 0.769, 2.089, 1.11, 1.269, 0.759, 1.176, 1.875, 1.448, 0.939, 1.445, 0.477, 1.542, 1.076, 1.373, 0.257, 1.32, 0.713, 1.087, 1.932, 0.989, 1.884, 2.074, 1.841, 1.155, 2.106, 1.018, 1.005, 2.027, 0.517, 2.326, 1.594, 1.202, 2.285, 1.715, 0.562, 1.481, 1.29, 1.302, 1.017, 0.304, 0.984, 0.662, 1.174, 0.62, 1.246, 1.273, 3.479, 0.427, 1.655, 1.709, 0.691, 2.139, 3.282, 1.533, 1.785, 1.257, 2.485, 0.618, 1.239, 1.647, 1.13, 0.426, 1.407, 2.056, 1.469, 2.913, 2.032, 3.61, 2.452, ...]</td>\n      <td>5931</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>DER_met_phi_centrality</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[1.396, 1.414, -1.285, -1.385, 0.479, 1.393, -1.305, -1.366, 0.538, -1.412, 1.364, 0.689, -1.414, -0.272, 0.218, 1.401, -1.351, -1.395, -1.178, -0.8, -1.409, 1.042, 1.353, 1.403, 1.306, 1.061, -1.318, 0.838, 1.355, 1.337, 0.655, -1.405, -1.408, 0.023, 1.171, -0.797, 1.025, -1.377, -1.367, -0.776, 1.408, -1.403, -1.406, -1.382, 1.407, -0.574, -1.331, -1.337, -1.411, -1.393, 0.558, 1.389, -1.34, 1.287, -1.361, 1.397, -1.304, 1.329, 0.089, 1.404, -0.909, 0.136, 1.4, -0.875, -1.39, -1.407, -1.359, -1.398, -0.7, -0.24, 1.286, -1.375, -1.372, 1.31, 1.41, 0.677, -1.349, -0.112, -1.284, -1.101, -1.381, 0.308, 1.312, -1.341, -1.391, 0.227, 0.572, 1.335, 1.405, 1.411, 1.199, -1.324, 1.362, 0.618, 1.402, -1.3, -1.091, 1.369, 1.392, -1.413, ...]</td>\n      <td>2829</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>DER_lep_eta_centrality</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[0.2, -999.0, 0.975, 0.791, 0.769, 0.207, 0.696, 0.982, 0.984, 0.82, 0.929, 0.0, 0.631, 0.024, 0.688, 0.991, 0.001, 0.959, 0.585, 0.434, 0.422, 0.998, 0.159, 0.677, 0.475, 0.895, 0.328, 0.061, 0.251, 0.656, 0.995, 0.601, 0.396, 0.543, 0.401, 0.636, 0.398, 0.892, 0.524, 0.09, 0.611, 0.691, 0.014, 0.056, 0.448, 1.0, 0.306, 0.077, 0.932, 0.988, 0.792, 0.617, 0.883, 0.961, 0.48, 0.318, 0.175, 0.427, 0.968, 0.743, 0.111, 0.752, 0.946, 0.574, 0.999, 0.291, 0.945, 0.186, 0.994, 0.92, 0.417, 0.299, 0.218, 0.732, 0.715, 0.894, 0.777, 0.952, 0.985, 0.105, 0.002, 0.593, 0.57, 0.914, 0.922, 0.117, 0.649, 0.993, 0.008, 0.851, 0.204, 0.84, 0.491, 0.76, 0.399, 0.584, 0.788, 0.863, 0.018, 0.273, ...]</td>\n      <td>1002</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>PRI_tau_pt</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[32.638, 42.014, 32.154, 22.647, 28.209, 53.651, 28.85, 78.8, 39.008, 54.646, 29.718, 35.976, 62.89, 25.47, 22.552, 30.606, 30.145, 30.739, 27.931, 31.046, 27.453, 37.06, 28.688, 98.565, 21.751, 23.319, 34.657, 24.899, 37.999, 49.624, 29.267, 126.071, 37.764, 26.075, 48.605, 25.085, 57.869, 56.845, 21.326, 39.107, 42.787, 22.566, 77.097, 34.371, 35.311, 26.365, 102.618, 40.193, 72.924, 32.531, 24.759, 23.515, 29.005, 25.232, 24.198, 21.631, 73.982, 35.306, 30.0, 61.114, 22.375, 30.409, 24.676, 23.815, 26.803, 52.772, 28.94, 26.665, 22.455, 39.923, 93.741, 35.66, 40.271, 30.428, 53.443, 80.853, 28.542, 29.167, 76.021, 21.816, 21.429, 39.441, 31.234, 23.845, 20.039, 30.651, 32.441, 21.432, 94.921, 36.337, 28.485, 33.317, 64.293, 20.535, 20.651, 31.581, 36.695, 41.804, 21.617, 21.977, ...]</td>\n      <td>59639</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>PRI_tau_eta</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[1.017, 2.039, -0.705, -1.655, -2.197, 0.371, 1.113, 0.654, 2.433, -1.533, -0.866, -0.669, -0.766, -0.654, 1.389, -1.107, 0.484, -0.635, 1.175, 1.38, 1.58, 1.537, 1.739, 0.19, -0.709, -0.081, 1.587, -0.089, -0.214, -1.093, -1.346, 0.953, 0.215, -0.175, -2.123, -0.251, -0.428, -0.935, 1.459, -1.081, -1.942, 1.645, -0.303, -1.723, 1.323, 0.664, -1.475, -1.06, -0.14, 0.801, -1.063, 0.948, -1.272, 0.167, 1.099, 0.872, -0.767, -1.987, -2.443, 2.02, -0.595, 0.805, 2.452, -0.828, -0.034, 1.979, 2.288, 1.102, -1.201, 1.337, 1.963, 0.675, 0.557, -2.097, 1.804, -0.714, 0.563, -0.476, 1.769, 0.184, 2.445, 0.266, -0.64, -0.185, -0.56, -0.33, -0.735, 0.71, 0.105, -0.567, -0.684, 2.077, 0.418, 0.186, 1.013, -1.728, 0.218, -1.298, -1.268, 1.603, ...]</td>\n      <td>4971</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>PRI_tau_phi</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[0.381, -3.011, -2.093, 0.01, -2.231, 1.329, 2.409, 1.547, -2.532, 0.416, 2.878, -0.342, -1.632, -2.99, 1.34, -1.903, -0.929, 2.603, 2.356, 0.451, 2.51, -2.616, -2.975, -1.506, -1.088, -0.338, -2.342, -2.678, 1.995, -0.333, 2.492, 0.74, -0.782, -3.018, 3.006, 0.614, 2.009, -1.615, 1.431, -0.574, -2.03, -2.694, -2.546, 2.505, 1.693, -0.659, 0.934, 1.014, 0.332, -2.167, -1.525, -0.454, -2.41, -2.822, -1.698, -2.864, -2.933, -1.803, 1.353, -1.579, -0.472, 1.37, 3.075, -3.099, 2.793, -2.445, 0.175, 1.183, 0.062, 0.441, -1.441, 1.567, 1.066, 1.477, -1.877, 2.973, 1.972, -1.902, -0.567, -0.062, -2.622, 2.945, 1.128, -2.606, 0.131, -0.658, -3.107, 2.08, -0.014, 1.874, 1.002, -2.566, -1.546, -1.804, 0.782, -0.563, 1.93, -1.114, -0.643, 1.827, ...]</td>\n      <td>6285</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>PRI_lep_pt</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[51.626, 36.918, 121.409, 53.321, 29.774, 31.565, 97.24, 28.74, 26.325, 32.742, 52.016, 38.188, 36.237, 33.179, 40.013, 39.043, 34.522, 48.764, 43.512, 27.165, 29.704, 27.773, 36.594, 64.285, 56.137, 34.797, 44.897, 70.923, 44.523, 76.454, 50.292, 32.986, 29.054, 54.476, 53.933, 31.832, 43.919, 66.859, 39.994, 56.61, 40.158, 32.616, 36.746, 53.003, 38.009, 36.2, 26.334, 53.062, 51.962, 35.363, 47.83, 34.912, 44.302, 60.168, 46.447, 27.952, 45.546, 75.348, 35.478, 60.803, 31.599, 52.034, 48.47, 29.67, 54.41, 45.97, 29.656, 42.862, 34.406, 29.231, 40.602, 28.464, 35.076, 26.677, 35.723, 33.137, 100.761, 36.328, 101.483, 32.459, 36.095, 36.623, 27.269, 66.796, 78.248, 30.712, 54.696, 40.785, 53.255, 58.684, 45.014, 46.906, 37.638, 27.393, 28.883, 42.46, 46.402, 106.897, 84.954, 78.034, ...]</td>\n      <td>61929</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>PRI_lep_eta</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[2.273, 0.501, -0.953, -0.522, 0.798, -0.884, 0.675, 0.506, 0.21, -0.317, 0.126, -0.165, 0.722, -1.665, 1.856, -1.944, -0.215, -0.343, 2.332, -1.486, 0.341, 1.161, 2.367, 1.405, 0.531, -0.321, 1.664, -0.98, -1.354, -0.595, -2.443, 0.231, -0.575, 1.026, -0.456, -0.357, -0.1, -1.357, -1.133, -1.185, -1.218, 1.287, -0.758, -1.181, 1.526, 0.656, -1.281, -0.374, 0.266, 0.826, 1.347, 1.605, 1.66, 0.918, -2.127, 0.457, -0.107, -1.992, -2.046, 1.905, -1.398, 0.814, 1.948, -0.541, -0.249, 2.125, 1.748, 0.519, -0.344, 1.411, 1.174, 1.294, 1.736, -2.163, 2.193, -0.668, 1.4, -2.124, 0.362, 0.083, 1.377, 0.718, 0.793, -0.917, 0.418, -1.988, 2.183, 1.292, 0.803, 2.317, -1.402, 0.354, 0.01, -0.71, -0.616, -1.721, 1.648, -1.866, -1.216, 1.873, ...]</td>\n      <td>4987</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>PRI_lep_phi</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[-2.414, 0.103, 1.052, -3.1, 1.569, 1.857, -0.966, -1.347, 1.884, -0.636, -1.288, 2.502, -0.035, -0.354, 1.412, 1.191, 1.941, -0.862, 0.584, 0.724, 1.869, 1.335, -0.193, -0.952, 1.679, 2.564, 1.17, -0.783, -1.064, 0.836, -1.046, -2.899, -2.914, 2.944, -1.308, 0.823, -2.842, -1.397, -1.869, -1.032, 2.074, 0.574, 1.764, 0.355, -1.44, 2.474, -0.913, 2.681, -2.603, -2.227, -2.569, 1.758, -2.567, 2.033, 1.419, -0.755, 1.769, -1.441, -0.125, 2.908, 2.648, 1.413, 2.429, -2.19, -0.705, -1.027, -0.495, 1.4, 1.725, -1.421, -2.364, 2.05, 2.811, -1.256, -0.908, -0.932, 0.855, 1.929, -2.989, 2.615, 2.954, 2.02, 1.174, -0.056, 0.119, -1.514, 0.439, -2.831, 0.172, -1.888, -2.996, -1.382, -3.097, 2.091, 2.404, 0.616, -2.54, -0.937, 2.739, 2.688, ...]</td>\n      <td>6285</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>PRI_met</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[16.824, 44.704, 54.283, 31.082, 2.723, 40.735, 38.421, 22.275, 37.791, 132.678, 51.276, 22.385, 43.91, 12.439, 75.197, 19.959, 41.899, 17.557, 44.698, 72.981, 67.909, 27.431, 12.556, 17.96, 27.318, 10.098, 32.07, 69.364, 39.141, 26.438, 44.156, 65.09, 45.253, 23.618, 10.096, 12.563, 11.797, 16.589, 18.093, 2.713, 20.195, 29.74, 27.921, 21.006, 17.651, 32.195, 47.249, 14.532, 23.577, 4.67, 28.499, 24.104, 41.305, 42.635, 31.593, 28.169, 73.398, 86.93, 17.674, 39.933, 59.825, 25.922, 30.839, 36.512, 16.44, 23.701, 30.361, 36.135, 52.175, 46.471, 11.126, 75.369, 36.787, 13.736, 36.227, 36.055, 39.99, 12.569, 37.422, 52.567, 18.405, 32.276, 69.34, 20.804, 105.389, 43.206, 43.135, 28.662, 53.22, 68.732, 13.612, 18.813, 32.406, 36.296, 85.179, 29.147, 15.11, 25.565, 50.145, 27.167, ...]</td>\n      <td>87836</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>PRI_met_phi</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[-0.277, -1.916, -2.186, 0.06, -0.871, 2.237, -1.443, -1.761, 0.024, 0.845, 0.688, 2.148, -1.907, 1.433, -1.583, 2.415, 2.055, -2.975, -2.033, -2.577, -1.169, 0.645, 2.008, -0.973, -0.716, -1.397, -2.891, -1.173, -1.127, 1.15, 2.595, -2.769, 1.204, -1.209, 2.976, 1.915, -1.739, 0.923, -0.299, 1.29, -2.516, -2.484, -2.719, 3.141, -0.023, -0.498, -1.577, 0.104, -1.342, -0.233, 0.96, -3.099, 0.183, -1.54, -1.263, 1.469, -0.785, -1.044, -0.684, 0.877, 1.668, -1.913, 0.061, 0.692, -2.79, 2.686, -3.01, -1.794, 1.337, 1.425, -0.788, -2.499, -0.432, -2.121, 3.073, -2.228, -3.012, 0.1, -1.862, -2.277, 0.296, -1.758, 1.541, 2.299, -0.168, 1.27, 2.327, 2.117, 2.743, -0.977, -1.16, 1.566, -0.926, 1.542, 2.816, -3.011, 0.234, -1.611, 1.565, 3.134, ...]</td>\n      <td>6285</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>PRI_met_sumet</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[258.733, 164.546, 260.414, 86.062, 53.131, 282.849, 294.074, 187.299, 129.804, 294.741, 250.178, 290.547, 232.362, 163.42, 198.616, 122.176, 191.568, 211.72, 151.816, 115.145, 225.139, 169.061, 68.527, 454.785, 253.577, 93.086, 82.224, 289.876, 175.843, 357.815, 157.431, 515.415, 199.861, 309.43, 195.864, 152.875, 241.281, 95.267, 453.69, 243.867, 59.902, 70.266, 275.222, 68.796, 176.82, 233.334, 337.398, 118.867, 319.578, 70.691, 90.355, 202.281, 104.743, 146.821, 106.965, 54.023, 185.682, 521.36, 149.85, 283.314, 402.277, 89.716, 162.628, 84.621, 215.024, 214.474, 222.183, 218.411, 326.007, 126.9, 337.559, 169.293, 148.77, 124.752, 123.357, 135.433, 170.842, 215.393, 325.373, 273.452, 29.742, 32.944, 453.141, 198.904, 392.838, 72.211, 277.402, 146.893, 111.693, 290.533, 390.63, 40.3, 103.858, 261.442, 147.129, 52.207, 97.737, 432.241, 351.78, 327.422, ...]</td>\n      <td>179740</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>PRI_jet_num</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>[2, 1, 0, 3]</td>\n      <td>4</td>\n      <td>0:99913<br>1:77544<br>2:50379<br>3:22164</td>\n    </tr>\n    <tr>\n      <th>PRI_jet_leading_pt</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[67.435, 46.226, 44.251, -999.0, 90.547, 123.01, 30.638, 167.735, 76.773, 93.117, 36.263, 195.533, 35.527, 170.712, 77.221, 80.627, 33.25, 182.449, 81.17, 71.127, 45.843, 46.679, 114.602, 88.399, 98.198, 37.734, 86.447, 50.396, 69.371, 40.581, 214.449, 80.042, 78.174, 31.238, 45.355, 38.504, 83.996, 59.401, 36.367, 56.951, 101.934, 116.316, 74.841, 85.392, 39.577, 176.49, 87.198, 33.828, 40.334, 86.379, 66.27, 89.475, 97.16, 111.656, 95.352, 62.766, 135.815, 90.445, 73.26, 66.774, 78.35, 55.814, 36.929, 127.907, 42.484, 62.07, 148.174, 78.949, 86.119, 31.574, 52.929, 111.193, 58.769, 132.014, 59.282, 32.519, 30.071, 40.035, 51.155, 113.256, 84.061, 52.541, 43.305, 115.476, 31.569, 72.406, 34.663, 146.463, 47.261, 93.768, 42.147, 32.643, 79.183, 38.067, 51.688, 78.116, 32.329, 67.094, 80.927, 33.304, ...]</td>\n      <td>86590</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>PRI_jet_leading_eta</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[2.15, 0.725, 2.053, -999.0, -2.412, 0.864, -0.715, -2.767, -0.79, -0.97, -0.766, 1.156, 4.347, -1.961, -0.049, 0.993, -3.199, 1.383, 3.102, 2.177, 1.131, -1.711, 0.619, -2.168, 1.995, 2.663, -2.142, -0.708, -0.548, -3.062, -0.058, -0.856, -1.668, -2.123, -0.977, 2.526, -0.953, 1.342, -1.891, 0.749, 3.139, -1.171, 0.616, -1.062, 2.871, -0.558, -2.031, -0.454, -0.965, 1.365, 2.045, -1.828, -1.686, -0.987, -0.825, 0.778, -2.087, -1.63, -1.915, 0.01, -3.092, 3.716, -0.194, 1.837, 0.845, 1.846, 1.109, -1.634, 2.199, 2.97, -1.836, 0.243, -3.163, 1.418, 2.033, 1.142, -0.909, -0.284, 0.122, 2.447, -0.771, 0.194, -0.855, -3.444, -2.689, 1.713, -2.567, 0.737, 1.146, -2.97, -1.42, 1.395, 0.046, -2.225, 0.478, -0.619, -3.569, 0.001, 1.951, -1.366, ...]</td>\n      <td>8558</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>PRI_jet_leading_phi</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[0.444, 1.158, -2.028, -999.0, -0.653, 1.45, -1.724, -2.514, 0.303, 1.943, -0.686, 1.416, -0.169, 2.22, 1.426, -2.018, 2.057, 0.001, -0.977, 0.558, 1.15, -1.864, 0.165, -1.423, 0.961, -0.491, 0.298, -0.642, 0.57, 2.144, 1.525, 1.304, -0.978, -2.415, 1.973, 0.914, -1.522, -0.369, 1.316, -0.296, 0.641, -1.564, 0.166, -2.316, 2.664, -2.452, -1.074, 0.94, 0.155, 0.05, -0.48, 2.858, -0.035, -0.201, -2.209, -2.199, -1.166, -1.662, -2.731, 0.136, -2.343, -0.806, -1.936, 2.605, 1.258, -1.21, 2.421, 2.361, -0.621, 1.067, 0.454, 0.694, 1.894, 2.603, -2.585, -0.924, 1.835, -2.564, -0.797, -1.501, -0.861, -1.103, -1.756, 0.982, -0.295, 0.633, 0.735, 2.157, 1.909, 2.535, -2.178, -1.537, -2.201, -1.426, -1.302, 0.877, -2.511, -2.954, 0.31, 0.571, ...]</td>\n      <td>6285</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>PRI_jet_subleading_pt</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[46.062, -999.0, 56.165, 56.867, 56.876, 82.477, 43.458, 32.625, 38.006, 55.092, 32.515, 77.053, 77.27, 85.448, 32.666, 32.332, 46.094, 30.442, 56.31, 52.501, 58.097, 42.588, 53.711, 42.88, 70.786, 81.559, 36.863, 73.566, 80.424, 48.707, 42.808, 92.256, 38.135, 39.356, 58.965, 41.357, 31.47, 62.761, 41.496, 39.226, 140.818, 55.71, 41.671, 44.163, 81.532, 41.913, 67.594, 31.252, 43.856, 53.862, 30.079, 66.832, 35.2, 31.027, 33.502, 35.965, 54.651, 32.081, 84.756, 115.897, 51.029, 57.993, 203.159, 69.051, 74.298, 90.264, 57.914, 61.046, 46.951, 112.337, 92.879, 56.255, 42.907, 31.624, 32.626, 43.81, 39.927, 36.71, 41.781, 30.544, 63.49, 39.712, 41.717, 51.68, 39.063, 38.487, 47.204, 61.154, 35.686, 132.52, 106.525, 42.602, 78.908, 50.443, 109.038, 31.277, 34.852, 52.842, 39.414, 70.039, ...]</td>\n      <td>42464</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>PRI_jet_subleading_eta</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[1.24, -999.0, 0.224, 0.131, 1.773, -0.798, 2.974, -2.683, -1.257, -1.985, -0.983, 2.433, -2.385, -1.285, 1.293, 2.295, 3.392, -2.58, 1.151, 0.638, -0.989, 3.604, -2.577, -2.229, 0.513, -1.793, 0.49, 0.639, -4.063, 1.557, 1.617, 3.625, -1.85, 0.833, 1.107, 2.695, 0.563, 0.824, -4.023, 0.796, -3.779, 1.343, 0.82, -2.314, 0.2, 2.14, -1.788, 3.195, -1.87, -0.787, 0.287, 0.72, 1.749, -0.954, -0.57, 3.144, -0.726, 0.236, 0.352, -0.861, -0.149, 0.128, 2.876, -0.881, -1.189, 3.279, -1.299, 1.443, -1.997, 2.202, -3.298, -0.115, 2.854, 3.576, 3.039, 0.841, 1.949, 0.919, -0.305, 2.206, -0.256, -2.19, -0.002, 2.978, 0.4, -2.701, -1.414, -1.708, 0.616, -3.691, -1.082, -1.575, -1.874, 0.3, 2.381, -2.891, -2.155, -2.638, -2.276, 0.323, ...]</td>\n      <td>8628</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>PRI_jet_subleading_phi</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[-2.475, -999.0, 3.106, -2.767, -2.079, -2.785, -0.103, -1.467, -0.609, 3.065, -2.628, -2.637, 1.876, -0.995, -2.358, -2.273, -1.725, 2.396, -1.743, -1.114, -1.727, -2.122, 2.14, -2.825, -0.567, -2.255, 1.295, -1.616, 3.118, -1.319, 1.534, -1.433, 2.93, 0.49, 3.092, 1.3, 1.342, 1.908, 2.314, 1.344, 0.213, 1.587, 1.655, 1.503, -1.402, -1.937, -0.287, -0.748, -0.189, -1.39, 2.168, 0.189, -1.407, 0.255, 0.219, 0.688, -2.802, -2.231, -0.622, -2.181, -0.608, 0.95, 1.316, 1.982, 0.405, 3.052, -1.247, 1.946, 1.045, -0.139, -3.013, 0.79, -1.133, -1.364, -2.702, -0.484, 2.499, -0.025, 3.105, -0.293, -0.835, 1.265, 0.449, 0.534, 1.11, -1.868, -1.439, 1.67, -1.941, 1.667, 3.086, 2.441, 0.105, -2.855, -0.481, -0.228, 1.634, -0.849, -1.601, -2.068, ...]</td>\n      <td>6286</td>\n      <td>HC</td>\n    </tr>\n    <tr>\n      <th>PRI_jet_all_pt</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>[113.497, 46.226, 44.251, -0.0, 193.66, 179.877, 30.638, 167.735, 165.64, 93.117, 36.263, 278.009, 35.527, 214.17, 77.221, 113.252, 33.25, 253.461, 136.262, 103.642, 45.843, 46.679, 341.947, 198.632, 183.646, 70.4, 118.779, 50.396, 115.465, 71.023, 270.759, 182.413, 212.314, 31.238, 45.355, 38.504, 126.584, 162.577, 36.367, 140.06, 172.721, 116.316, 74.841, 343.858, 76.44, 333.586, 87.198, 33.828, 40.334, 224.195, 114.977, 89.475, 171.763, 203.911, 133.488, 62.766, 175.171, 234.979, 151.674, 98.243, 141.111, 97.31, 36.929, 127.907, 81.71, 62.07, 380.547, 78.949, 86.119, 31.574, 52.929, 166.904, 58.769, 132.014, 100.953, 32.519, 30.071, 40.035, 169.164, 194.789, 84.061, 128.049, 43.305, 183.07, 31.569, 103.658, 34.663, 190.319, 47.261, 263.03, 42.147, 32.643, 79.183, 68.147, 51.688, 144.949, 32.329, 67.094, 116.126, 33.304, ...]</td>\n      <td>103559</td>\n      <td>HC</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"Our dataset has one categorical variable and rest all continuous variable.","metadata":{}},{"cell_type":"code","source":"cat_vars=['PRI_jet_num']\ncont_vars=np.array(train_dataX.drop('PRI_jet_num',axis=1).columns)","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"cont_vars","metadata":{"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array(['DER_mass_MMC', 'DER_mass_transverse_met_lep', 'DER_mass_vis',\n       'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet',\n       'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot',\n       'DER_sum_pt', 'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality',\n       'DER_lep_eta_centrality', 'PRI_tau_pt', 'PRI_tau_eta',\n       'PRI_tau_phi', 'PRI_lep_pt', 'PRI_lep_eta', 'PRI_lep_phi',\n       'PRI_met', 'PRI_met_phi', 'PRI_met_sumet', 'PRI_jet_leading_pt',\n       'PRI_jet_leading_eta', 'PRI_jet_leading_phi',\n       'PRI_jet_subleading_pt', 'PRI_jet_subleading_eta',\n       'PRI_jet_subleading_phi', 'PRI_jet_all_pt'], dtype=object)"},"metadata":{}}]},{"cell_type":"markdown","source":"# EDA:","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(collections.Counter(train_dataY),index=['0','1']).iloc[0]\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*This shows that our dataset is highly imbalanced and we will be needing to do certain upsampling and downsampling in our data.*","metadata":{}},{"cell_type":"code","source":"fig,axes=plt.subplots(figsize=(10,8))\nprint(training['Label'].value_counts())\nsns.barplot(x = training['Label'].value_counts().index, y = training['Label'].value_counts().values)\nplt.title('Label counts')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*As we can see this is an unbalanced dataset, with more number of background events, characterised by 1 and less number of signal events characterised by 0*","metadata":{}},{"cell_type":"code","source":"ncols = 2\nnrows = math.ceil(len(cont_vars)/ncols)\nfig, axen = plt.subplots(nrows, ncols, figsize = (12, nrows*4))\nfor v, ax in zip(cont_vars, axen.ravel()):\n    sns.histplot(train_dataX[v], ax=ax)\n    ax.set_xscale('log')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#viz = plot_corr_heatmap(train_dataX, figsize=(11,10))\n#viz.save('corrheatmap.svg')\n#viz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(data=train_dataX[cont_vars])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"D = feature_dependence_matrix(train_dataX)\nviz = plot_dependence_heatmap(D, figsize=(11,10))\nviz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Here we have got hold of the multiple dependencies of the different variables. We will eliminate the collinearity of the variables while checking for the fearure importances post modelling.*","metadata":{}},{"cell_type":"markdown","source":"# Models:","metadata":{}},{"cell_type":"markdown","source":"#### Helper Function:","metadata":{}},{"cell_type":"code","source":"def cv_optimize(clf, parameters, X, y, n_jobs=1, n_folds=5, score_func=None):\n    if score_func:\n        print(\"SCORE FUNC\", score_func)\n        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, n_jobs=n_jobs, scoring=score_func)\n    else:\n        gs = GridSearchCV(clf, param_grid=parameters, n_jobs=n_jobs, cv=n_folds)\n    gs.fit(X, y)\n    print(\"BEST\", gs.best_params_, gs.best_score_)\n    best = gs.best_estimator_\n    return best\ndef do_classify(clf, parameters, indf,y,score_func, n_folds=5, n_jobs=1):\n    X=indf\n    y=y\n    Xtrain,Xtest,ytrain,ytest=train_test_split(X,y,train_size=0.8,random_state=2017)\n    clf = cv_optimize(clf, parameters, Xtrain, ytrain, n_jobs=n_jobs, n_folds=n_folds, score_func=score_func)\n    clf=clf.fit(Xtrain, ytrain)\n    training_accuracy = clf.score(Xtrain, ytrain)\n    test_accuracy = clf.score(Xtest, ytest)\n    print(\"############# based on standard predict ################\")\n    print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n    print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))\n    print(confusion_matrix(ytest, clf.predict(Xtest)))\n    print(\"########################################################\")\n    plot_confusion_matrix(clf,Xtest,ytest,cmap=\"Blues\")\n    return clf, Xtrain, ytrain, Xtest,ytest","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Baseline Model using LogisticRegression:","metadata":{}},{"cell_type":"code","source":"# set up standardization\nss = StandardScaler()\n# oe hot encoding\noh = OneHotEncoder()\n# continuous variables need to be standardized\ncont_pipe = Pipeline([(\"scale\", ss)])\n# categorical variables need to be one hot encoded\ncat_pipe = Pipeline([('onehot', oh)])\n# combine both into a transformer\ntransformers = [('cont', cont_pipe, cont_vars), ('cat', cat_pipe, cat_vars)]\n# apply transformer to relevant columns. Nothing will be done for the rest\nct = ColumnTransformer(transformers=transformers, remainder=\"passthrough\")\n# create a pipeline so that we are not leaking data from validation to train in the individual folds\npipe = Pipeline(steps=[('ct', ct), ('model', LogisticRegression(max_iter=10000, penalty='l2'))])\n# in paramgrid we dont use C but use model__C corresponding to the name in the pipeline\nparamgrid = dict(model__C=[1000, 100, 10, 1, 0.1, 0.01, 0.001])\n\nlr,Xtrain,ytrain,Xtest,ytest=do_classify(pipe, paramgrid,train_dataX, \n                              train_dataY, \n                              score_func='roc_auc')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(ytest,lr.predict(Xtest)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*The imbalance is causing the accuracy issue for predicting the the signal event. Hence, we will balance the dataset by upsampling and downsampling.*","metadata":{}},{"cell_type":"markdown","source":"### Upsampling and DownSampling:","metadata":{}},{"cell_type":"code","source":"over = SMOTE(sampling_strategy='auto', k_neighbors=2)\nunder = RandomUnderSampler(sampling_strategy='auto')\nsteps = [('o', over), ('u', under)]\npipeline = imblearn.pipeline.Pipeline(steps=steps)\nX, y = pipeline.fit_resample(train_dataX,train_dataY)\ncounter = collections.Counter(y)\nprint(counter)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Baseline Model using Decision Tree Classifier:","metadata":{}},{"cell_type":"code","source":"!pip install dtreeviz\nfrom dtreeviz.trees import dtreeviz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf=DecisionTreeClassifier(random_state=2017)\nparameters={'max_depth':range(1,9),'min_samples_leaf':range(3,5),'criterion':['gini']}\nclf, Xtrain, ytrain, Xtest,ytest=do_classify(clf, parameters,train_dataX,train_dataY,'roc_auc',n_folds=5,n_jobs=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(ytest,clf.predict(Xtest)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = [None,  # 0 classes\n          None,  # 1 class\n          ['#FFF4E5','#D2E3EF'],# 2 classes\n           ]\nvizA = dtreeviz(clf, train_dataX,train_dataY,\n               feature_names = train_dataX.columns,\n               target_name = 'Label', class_names= ['No','Yes']\n              ,orientation = 'TD',\n               colors={'classes':colors},\n               label_fontsize=14,\n               ticks_fontsize=10,\n               )\nvizA","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vizA.save('tree.svg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Although the dataset is imbalanced,the decision tree seems to do a decent job wrt to handling the imbalance**","metadata":{}},{"cell_type":"code","source":"\ndef p_importance(model, cols, fi, fistd = 0):\n    return pd.DataFrame({'features':cols, 'importance':fi, 'importance_std': fistd}\n                       ).sort_values('importance', ascending=False)\ndimp=permutation_importance(clf,Xtest,ytest)\nddf=p_importance(clf,list(train_dataX.columns),dimp['importances_mean'],dimp['importances_std']).iloc[:10]\nfig,ax=plt.subplots(figsize=(17,10))\nsns.barplot(data=ddf,x='features',y='importance',label='Decision_importances',ax=ax)\nplt.xticks(rotation='45')\nplt.title(\"Bar plot of Importances for Decision Tree Model\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"D = D['Dependence'].sort_values(ascending=False)\nD","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**we see in the dependences and importance plots, the most dependent variables are the least important amongst the top 10 as well.**","metadata":{}},{"cell_type":"code","source":"##taking only those features which are important\nfeatures=['DER_mass_MMC','DER_mass_transverse_met_lep','DER_mass_vis','DER_deltar_tau_lep','PRI_tau_pt','DER_met_phi_centrality','DER_pt_h','PRI_met']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf=DecisionTreeClassifier(random_state=2017)\nparameters={'max_depth':range(1,9),'min_samples_leaf':range(3,5),'criterion':['gini']}\nclf, Xtrain, ytrain, Xtest,ytest=do_classify(clf, parameters,X[features],y,'roc_auc',n_folds=5,n_jobs=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(ytest,clf.predict(Xtest)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = [None,  # 0 classes\n          None,  # 1 class\n          ['#FFF4E5','#D2E3EF'],# 2 classes\n           ]\nvizb = dtreeviz(clf, Xtest[features],ytest,\n               feature_names = X[features].columns,\n               target_name = 'Label', class_names= ['No','Yes']\n              ,orientation = 'TD',\n               colors={'classes':colors},\n               label_fontsize=14,\n               ticks_fontsize=10,\n               )\nvizb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vizb.save('tree2.svg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest Classifier:","metadata":{}},{"cell_type":"code","source":"clf2=RandomForestClassifier(random_state=2017)\nparameters={\"n_estimators\":[400],'max_features':[3],'max_depth':[5]}\nclf2, Xtrain, ytrain, Xtest, ytest  = do_classify(clf2, \n   parameters,train_dataX[features],train_dataY,\"roc_auc\", n_folds=5, n_jobs=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(ytest,clf2.predict(Xtest)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*We do the same now with the balanced dataset.*","metadata":{}},{"cell_type":"code","source":"\nrimp=permutation_importance(clf2,Xtest,ytest)\nrdf=p_importance(clf2,features,rimp['importances_mean'],rimp['importances_std'])\nfig,ax=plt.subplots(figsize=(17,10))\nsns.barplot(data=rdf,x='features',y='importance',label='RandomForest_importances',ax=ax)\nplt.xticks(rotation='45')\nplt.title(\"Bar plot of Importances for Random Forest Model\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since, we know this is an imbalanced dataset, we will try out an upsampling downsampling for this purpose and run our model on the balanced dataset, to see how well our model does and if the upsampling helps.","metadata":{}},{"cell_type":"code","source":"clf2=RandomForestClassifier(random_state=2017)\nparameters={\"n_estimators\":[400],'max_features':[3],'max_depth':[5]}\nclf2, Xtrain, ytrain, Xtest, ytest  = do_classify(clf2, \n   parameters,X[features],y,\"roc_auc\", n_folds=5, n_jobs=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(ytest,clf2.predict(Xtest)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Boosting:","metadata":{}},{"cell_type":"markdown","source":"### Boosting without Balancing Dataset:","metadata":{}},{"cell_type":"code","source":"Xtrain,Xtest,ytrain,ytest=train_test_split(train_dataX[features],train_dataY,train_size=0.8)\nXtrain.shape,ytrain.shape\ndtrainimb=xgb.DMatrix(Xtrain,label=ytrain)\n\nclf3 = xgb.train(xgb_pars, dtrainimb, 500,\n                  maximize=False, verbose_eval=15) \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dvalid = xgb.DMatrix(Xtest, label=ytest)\ny_predimb=clf3.predict(dvalid)\ny_predimb_=[1 if y>0.5 else 0 for y in y_predimb]\nprint(classification_report(ytest,y_predimb_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Boosting with the Balanced Data:","metadata":{}},{"cell_type":"code","source":"Xtrain,Xtest,ytrain,ytest=train_test_split(X[features],y,train_size=0.8)\nXtrain.shape,ytrain.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtrain = xgb.DMatrix(Xtrain, label=ytrain)\ndvalid = xgb.DMatrix(Xtest, label=ytest)\n\nxgb_pars = {'min_child_weight': 100, 'eta': 0.04, 'colsample_bytree': 0.8, 'max_depth': 100,\n             'subsample': 0.75, 'lambda': 2, 'nthread': -1, 'booster' : 'gbtree', 'silent': 1, 'gamma' : 0,\n             'eval_metric': 'mae', 'objective': 'reg:linear'}    \n\nclf3 = xgb.train(xgb_pars, dtrain, 500,\n                  maximize=False, verbose_eval=15) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=clf3.predict(dvalid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_=[1 if y>0.5 else 0 for y in y_pred]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(ytest,y_pred_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Without the balancing of the dataset, the model runs poorly and hence the balancing.*","metadata":{}},{"cell_type":"markdown","source":"# Comparing the ROC curves:","metadata":{}},{"cell_type":"code","source":"\ndef make_roc(name, clf, ytest, xtest, ax=None, labe=5,  proba=True, skip=0, initial = False):\n    if not ax:\n        ax=plt.gca()\n    if proba:\n        fpr, tpr, thresholds=roc_curve(ytest, clf.predict_proba(xtest)[:,1])\n    else:\n        fpr, tpr, thresholds=roc_curve(ytest, clf.decision_function(xtest))\n    roc_auc = auc(fpr, tpr)\n    if skip:\n        l=fpr.shape[0]\n        ax.plot(fpr[0:l:skip], tpr[0:l:skip], '.-', lw=2, alpha=0.4, label='ROC curve for %s (area = %0.2f)' % (name, roc_auc))\n    else:\n        ax.plot(fpr, tpr, '.-', lw=2, alpha=0.4, label='ROC curve for %s (area = %0.2f)' % (name, roc_auc))\n    label_kwargs = {}\n    label_kwargs['bbox'] = dict(\n        boxstyle='round,pad=0.3', alpha=0.2,\n    )\n    for k in range(0, fpr.shape[0],labe):\n        #from https://gist.github.com/podshumok/c1d1c9394335d86255b8\n        threshold = str(np.round(thresholds[k], 2))\n        ax.annotate(threshold, (fpr[k], tpr[k]), **label_kwargs)\n    if initial:\n        ax.plot([0, 1], [0, 1], 'k--')\n        ax.set_xlim([0.0, 1.0])\n        ax.set_ylim([0.0, 1.05])\n        ax.set_xlabel('False Positive Rate')\n        ax.set_ylabel('True Positive Rate')\n        ax.set_title('ROC')\n    ax.legend(loc=\"lower right\")\n    return ax","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax=plt.subplots(figsize=(25,25))\nxtrain,xtest,ytr,yte=train_test_split(train_dataX,train_dataY,train_size=0.8)\nmake_roc('logistic', lr,yte ,xtest, ax=ax, labe=10,  proba=True, skip=16300, initial = False)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax=plt.subplots(figsize=(25,25))\nmake_roc('random', clf2,ytest ,Xtest, ax=ax, labe=10,  proba=True, skip=16300, initial = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax=plt.subplots(figsize=(25,25))\nmake_roc('decisiontree', clf,ytest ,Xtest, ax=ax, labe=10,  proba=True, skip=0, initial = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The ** ","metadata":{}},{"cell_type":"markdown","source":"### Recurrent Neural Networks \n\n*In a recurrent neural network we store the output activations from one or more of the layers of the network. Often these are hidden later activations. Then, the next time we feed an input example to the network, we include the previously-stored outputs as additional inputs. You can think of the additional inputs as being concatenated to the end of the “normal” inputs to the previous layer. For example, if a hidden layer had 10 regular input nodes and 128 hidden nodes in the layer, then it would actually have 138 total inputs (assuming you are feeding the layer’s outputs into itself à la Elman) rather than into another layer). Of course, the very first time you try to compute the output of the network you’ll need to fill in those extra 128 inputs with 0s or something.image.png\nRNNs are quite powerful, they suffer from Vanishing gradient problem which hinders them from using long term information, like they are good for storing memory 3-4 instances of past iterations but larger number of instances don't provide good results so we don't just use regular RNNs. Instead, we use a better variation of RNNs: Long Short Term Networks(LSTM).*","metadata":{}},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_df=training.drop('Weight',axis=1)","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"enc = LabelEncoder()\n\ntrain_df['Label'] = enc.fit_transform(train_df['Label'])\ntrain_df.head()","metadata":{"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"   EventId  DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\n0   100000       138.470                       51.655        97.827    27.980   \n1   100001       160.937                       68.768       103.235    48.146   \n2   100002      -999.000                      162.172       125.953    35.635   \n3   100003       143.905                       81.417        80.943     0.414   \n4   100004       175.864                       16.915       134.805    16.405   \n\n   DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n0                  0.91           124.711                2.666   \n1               -999.00          -999.000             -999.000   \n2               -999.00          -999.000             -999.000   \n3               -999.00          -999.000             -999.000   \n4               -999.00          -999.000             -999.000   \n\n   DER_deltar_tau_lep  DER_pt_tot  ...  PRI_met_sumet  PRI_jet_num  \\\n0               3.064      41.928  ...        258.733            2   \n1               3.473       2.078  ...        164.546            1   \n2               3.148       9.336  ...        260.414            1   \n3               3.310       0.414  ...         86.062            0   \n4               3.891      16.405  ...         53.131            0   \n\n   PRI_jet_leading_pt  PRI_jet_leading_eta  PRI_jet_leading_phi  \\\n0              67.435                2.150                0.444   \n1              46.226                0.725                1.158   \n2              44.251                2.053               -2.028   \n3            -999.000             -999.000             -999.000   \n4            -999.000             -999.000             -999.000   \n\n   PRI_jet_subleading_pt  PRI_jet_subleading_eta  PRI_jet_subleading_phi  \\\n0                 46.062                    1.24                  -2.475   \n1               -999.000                 -999.00                -999.000   \n2               -999.000                 -999.00                -999.000   \n3               -999.000                 -999.00                -999.000   \n4               -999.000                 -999.00                -999.000   \n\n   PRI_jet_all_pt  Label  \n0         113.497      1  \n1          46.226      0  \n2          44.251      0  \n3          -0.000      0  \n4           0.000      0  \n\n[5 rows x 32 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EventId</th>\n      <th>DER_mass_MMC</th>\n      <th>DER_mass_transverse_met_lep</th>\n      <th>DER_mass_vis</th>\n      <th>DER_pt_h</th>\n      <th>DER_deltaeta_jet_jet</th>\n      <th>DER_mass_jet_jet</th>\n      <th>DER_prodeta_jet_jet</th>\n      <th>DER_deltar_tau_lep</th>\n      <th>DER_pt_tot</th>\n      <th>...</th>\n      <th>PRI_met_sumet</th>\n      <th>PRI_jet_num</th>\n      <th>PRI_jet_leading_pt</th>\n      <th>PRI_jet_leading_eta</th>\n      <th>PRI_jet_leading_phi</th>\n      <th>PRI_jet_subleading_pt</th>\n      <th>PRI_jet_subleading_eta</th>\n      <th>PRI_jet_subleading_phi</th>\n      <th>PRI_jet_all_pt</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100000</td>\n      <td>138.470</td>\n      <td>51.655</td>\n      <td>97.827</td>\n      <td>27.980</td>\n      <td>0.91</td>\n      <td>124.711</td>\n      <td>2.666</td>\n      <td>3.064</td>\n      <td>41.928</td>\n      <td>...</td>\n      <td>258.733</td>\n      <td>2</td>\n      <td>67.435</td>\n      <td>2.150</td>\n      <td>0.444</td>\n      <td>46.062</td>\n      <td>1.24</td>\n      <td>-2.475</td>\n      <td>113.497</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100001</td>\n      <td>160.937</td>\n      <td>68.768</td>\n      <td>103.235</td>\n      <td>48.146</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.473</td>\n      <td>2.078</td>\n      <td>...</td>\n      <td>164.546</td>\n      <td>1</td>\n      <td>46.226</td>\n      <td>0.725</td>\n      <td>1.158</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>46.226</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100002</td>\n      <td>-999.000</td>\n      <td>162.172</td>\n      <td>125.953</td>\n      <td>35.635</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.148</td>\n      <td>9.336</td>\n      <td>...</td>\n      <td>260.414</td>\n      <td>1</td>\n      <td>44.251</td>\n      <td>2.053</td>\n      <td>-2.028</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>44.251</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100003</td>\n      <td>143.905</td>\n      <td>81.417</td>\n      <td>80.943</td>\n      <td>0.414</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.310</td>\n      <td>0.414</td>\n      <td>...</td>\n      <td>86.062</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-0.000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100004</td>\n      <td>175.864</td>\n      <td>16.915</td>\n      <td>134.805</td>\n      <td>16.405</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.891</td>\n      <td>16.405</td>\n      <td>...</td>\n      <td>53.131</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>0.000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df.set_index(['EventId'],inplace = True)\n","metadata":{"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"testing.shape,train_df.shape","metadata":{"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"((550000, 30), (250000, 31))"},"metadata":{}}]},{"cell_type":"code","source":"X = train_df.drop(['Label'], axis=1)\ny = train_df['Label'].values\nX = normalize(X)\ntest_df_nor = normalize(testing)","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#split to maintain the imbalance\nsplitter=StratifiedShuffleSplit(n_splits=1,random_state=12)\n\nfor train,test in splitter.split(X,y):     \n    X_train = X[train]\n    y_train = y[train]\n    X_test = X[test]\n    y_test = y[test]","metadata":{"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))\nX_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))","metadata":{"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import os\nimport csv\nimport math\n\n\ndef create_solution_dictionary(solution):\n    \"\"\" Read solution file, return a dictionary with key EventId and value (weight,label).\n    Solution file headers: EventId, Label, Weight \"\"\"\n    \n    solnDict = {}\n    with open(solution, 'rb') as f:\n        soln = csv.reader(f)\n        soln.next() # header\n        for row in soln:\n            if row[0] not in solnDict:\n                solnDict[row[0]] = (row[1], row[2])\n    return solnDict\ndef check_submission(submission, Nelements):\n    \"\"\" Check that submission RankOrder column is correct:\n        1. All numbers are in [1,NTestSet]\n        2. All numbers are unqiue\n    \"\"\"\n    rankOrderSet = set()    \n    with open(submission, 'rb') as f:\n        sub = csv.reader(f)\n        sub.next() # header\n        for row in sub:\n            rankOrderSet.add(row[1])\n            \n    if len(rankOrderSet) != Nelements:\n        print ('RankOrder column must contain unique values')\n        exit()\n    elif rankOrderSet.isdisjoint(set(xrange(1,Nelements+1))) == False:\n        print ('RankOrder column must contain all numbers from [1..NTestSset]')\n        exit()\n    else:\n        return True\n    def AMS(s, b):\n        \"\"\" Approximate Median Significance defined as:\n            AMS = sqrt(\n                    2 { (s + b + b_r) log[1 + (s/(b+b_r))] - s}\n                  )        \n        where b_r = 10, b = background, s = signal, log is natural logarithm \"\"\"\n\n        br = 10.0\n        radicand = 2 *( (s+b+br) * math.log (1.0 + s/(b+br)) -s)\n        if radicand < 0:\n            print ('radicand is negative. Exiting')\n            exit()\n        else:\n            return math.sqrt(radicand)\n    def AMS_metric(solution, submission):\n        \"\"\"  Prints the AMS metric value to screen.\n        Solution File header: EventId, Class, Weight\n        Submission File header: EventId, RankOrder, Class\n        \"\"\"\n\n        numEvents = 550000 # number of events = size of test set\n\n        # solutionDict: key=eventId, value=(label, class)\n        solutionDict = create_solution_dictionary(solution)\n\n        signal = 0.0\n        background = 0.0\n        if check_submission(submission, numEvents):\n            with open(submission, 'rb') as f:\n                sub = csv.reader(f)\n                sub.next() # header row\n                for row in sub:\n                    if row[2] == 's': # only events predicted to be signal are scored\n                        if solutionDict[row[0]][0] == 's':\n                            signal += float(solutionDict[row[0]][1])\n                        elif solutionDict[row[0]][0] == 'b':\n                            background += float(solutionDict[row[0]][1])\n\n            print ('signal = {0}, background = {1}'.format(signal, background))\n            print ('AMS = ' + str(AMS(signal, background)))\n\n\n        if __name__ == \"__main__\":\n\n            # enter path and file names here    \n            path = \"\"\n            solutionFile = \"\"\n            submissionFile = \"\"","metadata":{"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def build_rnn_model(train_x,train_y,test_x,test_y):\n    inp = Input(shape=(train_x.shape[1],train_x.shape[2]))\n    rnn_1st_model = LSTM(units=60, return_sequences=True,recurrent_dropout=0.1)(inp)\n    rnn_2nd_model = LSTM(units=60,recurrent_dropout=0.1)(rnn_1st_model)\n    dense_layer = Dense(128)(rnn_2nd_model)\n    drop_out = Dropout(0.2)(dense_layer)\n    output = Dense(1, activation= LeakyReLU(alpha=0.1),name=\"class\")(drop_out)\n    model = Model(inp, output)\n    callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=4, verbose=1, factor=0.6),\n                 EarlyStopping(monitor='val_loss', patience=20),\n                 ModelCheckpoint(filepath='best_model_LSTM.h5', monitor='val_loss', save_best_only=True)]\n    model.summary()\n    model.compile(loss=[tf.keras.losses.MeanSquaredLogarithmicError(),\n                        tf.keras.losses.MeanSquaredLogarithmicError()], optimizer=\"adam\")\n    history = model.fit(train_x, train_y, \n          epochs = 40, \n          batch_size = 100, \n          validation_data=(test_x,  test_y), \n          callbacks=callbacks)\n    return history,model","metadata":{"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def plot_Loss(history):\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Loss over epochs')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='best')\n    plt.show()","metadata":{"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def Save_Result_To_Csv(model,model_name,csv_file):\n    test_pre = np.reshape(test_df_nor, (test_df_nor.shape[0],test_df_nor.shape[1],1))\n    model.load_weights(model_name)\n    prediction = model.predict(test_pre)\n    prediction =  np.where(prediction > 0.5, 1, 0)\n    prediction = pd.Series(prediction[:,0])\n    sub = pd.read_csv('../input/higgs-boson/random_submission.zip')\n    test_predict = pd.DataFrame({\"EventId\":sub['EventId'],\"RankOrder\":sub['RankOrder'],\"Class\":prediction})\n    test_predict['Class'] = test_predict['Class'].replace(1,'s')\n    test_predict['Class'] = test_predict['Class'].replace(0,'b')\n    test_predict.to_csv(csv_file,index=False)","metadata":{"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"history_RNN,Rnn_model = build_rnn_model(X_train,y_train,X_test,y_test)","metadata":{"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 30, 1)]           0         \n_________________________________________________________________\nlstm (LSTM)                  (None, 30, 60)            14880     \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 60)                29040     \n_________________________________________________________________\ndense (Dense)                (None, 128)               7808      \n_________________________________________________________________\ndropout (Dropout)            (None, 128)               0         \n_________________________________________________________________\nclass (Dense)                (None, 1)                 129       \n=================================================================\nTotal params: 51,857\nTrainable params: 51,857\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/40\n2250/2250 [==============================] - 147s 64ms/step - loss: 0.1048 - val_loss: 0.0976\nEpoch 2/40\n2250/2250 [==============================] - 143s 63ms/step - loss: 0.0986 - val_loss: 0.0970\nEpoch 3/40\n2250/2250 [==============================] - 143s 63ms/step - loss: 0.0982 - val_loss: 0.0923\nEpoch 4/40\n2250/2250 [==============================] - 143s 64ms/step - loss: 0.1207 - val_loss: 0.1295\nEpoch 5/40\n2250/2250 [==============================] - 143s 64ms/step - loss: 0.1312 - val_loss: 0.1291\nEpoch 6/40\n2250/2250 [==============================] - 142s 63ms/step - loss: 0.1251 - val_loss: 0.0959\nEpoch 7/40\n2250/2250 [==============================] - 142s 63ms/step - loss: 0.1197 - val_loss: 0.1290\n\nEpoch 00007: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\nEpoch 8/40\n2250/2250 [==============================] - 142s 63ms/step - loss: 0.1317 - val_loss: 0.1290\nEpoch 9/40\n2250/2250 [==============================] - 143s 63ms/step - loss: 0.1311 - val_loss: 0.1289\nEpoch 10/40\n2250/2250 [==============================] - 142s 63ms/step - loss: 0.1303 - val_loss: 0.1280\nEpoch 11/40\n2250/2250 [==============================] - 142s 63ms/step - loss: 0.1296 - val_loss: 0.1273\n\nEpoch 00011: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\nEpoch 12/40\n2250/2250 [==============================] - 142s 63ms/step - loss: 0.1297 - val_loss: 0.1271\nEpoch 13/40\n2250/2250 [==============================] - 142s 63ms/step - loss: 0.1295 - val_loss: 0.1262\nEpoch 14/40\n2250/2250 [==============================] - 142s 63ms/step - loss: 0.1286 - val_loss: 0.1262\nEpoch 15/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.1271 - val_loss: 0.0880\nEpoch 16/40\n2250/2250 [==============================] - 142s 63ms/step - loss: 0.0898 - val_loss: 0.0853\nEpoch 17/40\n2250/2250 [==============================] - 142s 63ms/step - loss: 0.0862 - val_loss: 0.0827\nEpoch 18/40\n2250/2250 [==============================] - 142s 63ms/step - loss: 0.0840 - val_loss: 0.0794\nEpoch 19/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.0800 - val_loss: 0.0743\nEpoch 20/40\n2250/2250 [==============================] - 142s 63ms/step - loss: 0.0773 - val_loss: 0.0735\nEpoch 21/40\n2250/2250 [==============================] - 142s 63ms/step - loss: 0.0762 - val_loss: 0.0724\nEpoch 22/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.0755 - val_loss: 0.0722\nEpoch 23/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.0750 - val_loss: 0.0723\nEpoch 24/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.0740 - val_loss: 0.0725\nEpoch 25/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.0735 - val_loss: 0.0722\nEpoch 26/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.0734 - val_loss: 0.0729\n\nEpoch 00026: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\nEpoch 27/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.0727 - val_loss: 0.0714\nEpoch 28/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.0727 - val_loss: 0.0709\nEpoch 29/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.0726 - val_loss: 0.0712\nEpoch 30/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.0726 - val_loss: 0.0713\nEpoch 31/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.0720 - val_loss: 0.0706\nEpoch 32/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.0718 - val_loss: 0.0708\nEpoch 33/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.0719 - val_loss: 0.0704\nEpoch 34/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.0718 - val_loss: 0.0705\nEpoch 35/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.0724 - val_loss: 0.0702\nEpoch 36/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.0718 - val_loss: 0.0710\nEpoch 37/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.0720 - val_loss: 0.0706\nEpoch 38/40\n2250/2250 [==============================] - 142s 63ms/step - loss: 0.0719 - val_loss: 0.0701\nEpoch 39/40\n2250/2250 [==============================] - 141s 63ms/step - loss: 0.0711 - val_loss: 0.0701\nEpoch 40/40\n2250/2250 [==============================] - 142s 63ms/step - loss: 0.0714 - val_loss: 0.0702\n","output_type":"stream"}]},{"cell_type":"code","source":"plot_Loss(history_RNN)","metadata":{"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"Save_Result_To_Csv(Rnn_model,\"./best_model_LSTM.h5\",\"submission_Rnn.csv\")","metadata":{"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"sub=pd.read_csv(\"./submission_Rnn.csv\")\nsub.head()\n","metadata":{"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"   EventId  RankOrder Class\n0   350000     416957     b\n1   350001      89624     b\n2   350002     519845     b\n3   350003     510885     s\n4   350004     455944     b","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EventId</th>\n      <th>RankOrder</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>350000</td>\n      <td>416957</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>350001</td>\n      <td>89624</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>350002</td>\n      <td>519845</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>350003</td>\n      <td>510885</td>\n      <td>s</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>350004</td>\n      <td>455944</td>\n      <td>b</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}